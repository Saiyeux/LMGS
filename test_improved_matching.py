#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›åçš„åŒ¹é…æ€§èƒ½
"""

import sys
import cv2
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_improved_loftr():
    """æµ‹è¯•æ”¹è¿›åçš„LoFTRåŒ¹é…å™¨"""
    try:
        print("=== æµ‹è¯•æ”¹è¿›åçš„LoFTRåŒ¹é…å™¨ ===")
        
        from hybrid_slam.matchers.loftr_matcher import EfficientLoFTRMatcher
        
        # ä½¿ç”¨ä¸real_time_stereo_matcher.pyç›¸åŒçš„é…ç½®
        config = {
            'device': 'cpu',  # é¿å…CUDAé—®é¢˜
            'resize_to': [640, 480],  # è¿™ä¼šè¢«è°ƒæ•´ä¸ºèƒ½è¢«32æ•´é™¤çš„å°ºå¯¸
            'match_threshold': 0.15,  # ä½¿ç”¨æ›´åˆç†çš„é˜ˆå€¼
            'max_keypoints': 2048,
            'model_path': 'thirdparty/EfficientLoFTR/weights/eloftr_outdoor.ckpt',  # ä½¿ç”¨ç›¸åŒæƒé‡
            'enable_stereo_constraints': False
        }
        
        print(f"é…ç½®: {config}")
        
        # åˆ›å»ºåŒ¹é…å™¨
        print("åˆ›å»ºæ”¹è¿›çš„LoFTRåŒ¹é…å™¨...")
        matcher = EfficientLoFTRMatcher(config)
        
        if matcher.model is None:
            print("ERROR: æ¨¡å‹æœªåŠ è½½æˆåŠŸ")
            return False
        
        # æµ‹è¯•æ‘„åƒå¤´å›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if Path('camera_left_sample.jpg').exists() and Path('camera_right_sample.jpg').exists():
            print("æµ‹è¯•çœŸå®æ‘„åƒå¤´å›¾åƒ...")
            img1 = cv2.imread('camera_left_sample.jpg')
            img2 = cv2.imread('camera_right_sample.jpg')
        else:
            print("åˆ›å»ºæµ‹è¯•å›¾åƒ...")
            # åˆ›å»ºæ›´å¤æ‚çš„æµ‹è¯•å›¾åƒ
            img1 = np.zeros((480, 640, 3), dtype=np.uint8)
            img2 = np.zeros((480, 640, 3), dtype=np.uint8)
            
            # æ·»åŠ å¤æ‚çº¹ç†
            for i in range(0, 480, 30):
                for j in range(0, 640, 30):
                    if (i//30 + j//30) % 3 == 0:
                        img1[i:i+30, j:j+30] = [200, 200, 200]
                        img2[i:i+30, j:j+30] = [200, 200, 200]
                    elif (i//30 + j//30) % 3 == 1:
                        img1[i:i+30, j:j+30] = [100, 100, 100]
                        img2[i:i+30, j:j+30] = [100, 100, 100]
            
            # æ·»åŠ æ›´å¤šç‰¹å¾
            for x, y, r in [(150, 150, 25), (300, 200, 20), (450, 300, 30), (200, 400, 15)]:
                cv2.circle(img1, (x, y), r, (0, 255, 0), -1)
                cv2.circle(img2, (x-15, y), r, (0, 255, 0), -1)  # æ¨¡æ‹Ÿè§†å·®
                
                cv2.circle(img1, (x+100, y), r-5, (255, 0, 0), -1)
                cv2.circle(img2, (x+85, y), r-5, (255, 0, 0), -1)
            
            # æ·»åŠ çŸ©å½¢ç‰¹å¾
            cv2.rectangle(img1, (50, 50), (150, 100), (255, 255, 0), -1)
            cv2.rectangle(img2, (35, 50), (135, 100), (255, 255, 0), -1)
        
        print(f"å›¾åƒå°ºå¯¸: {img1.shape}")
        
        # æ‰§è¡ŒåŒ¹é…
        print("æ‰§è¡Œæ”¹è¿›çš„ç‰¹å¾åŒ¹é…...")
        matches, confidence = matcher.match_pair(img1, img2)
        
        if matches is None:
            print("ERROR: æ”¹è¿›åä»ç„¶æ²¡æœ‰æ‰¾åˆ°åŒ¹é…")
            return False
        
        num_matches = len(matches)
        print(f"âœ“ æ‰¾åˆ° {num_matches} ä¸ªåŒ¹é…ç‚¹")
        print(f"âœ“ å¹³å‡ç½®ä¿¡åº¦: {confidence:.3f}")
        
        # ä¸real_time_stereo_matcher.pyçš„æ•ˆæœå¯¹æ¯”
        if num_matches >= 20:
            print("ğŸ‰ SUCCESS: åŒ¹é…æ•°é‡æ˜¾è‘—æ”¹å–„ï¼")
        elif num_matches >= 10:
            print("âœ… GOOD: åŒ¹é…æ•°é‡æœ‰æ‰€æ”¹å–„")
        elif num_matches >= 5:
            print("âš ï¸  OK: åŒ¹é…æ•°é‡ä¸€èˆ¬")
        else:
            print("âŒ POOR: åŒ¹é…æ•°é‡ä»ç„¶å¾ˆå°‘")
        
        # åˆ›å»ºå¯è§†åŒ–
        if num_matches > 0:
            # ä½¿ç”¨ä¸real_time_stereo_matcher.pyç›¸åŒçš„å¯è§†åŒ–æ–¹å¼
            H0, W0 = img1.shape[:2]
            H1, W1 = img2.shape[:2]
            H = max(H0, H1)
            W = W0 + W1
            
            # è½¬æ¢ä¸ºç°åº¦ç”¨äºæ˜¾ç¤º
            if len(img1.shape) == 3:
                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
                gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            else:
                gray1, gray2 = img1, img2
            
            # åˆ›å»ºç»„åˆå›¾åƒ
            combined_img = np.zeros((H, W), dtype=np.uint8)
            combined_img[:H0, :W0] = gray1
            combined_img[:H1, W0:W0+W1] = gray2
            combined_img_color = cv2.cvtColor(combined_img, cv2.COLOR_GRAY2BGR)
            
            # ç»˜åˆ¶åŒ¹é…ç‚¹å’Œè¿çº¿
            for i, (pt1, pt2) in enumerate(matches[:50]):  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                if len(pt1) >= 2 and len(pt2) >= 2:
                    pt0 = tuple(map(int, pt1))
                    pt1_offset = tuple(map(int, pt2 + np.array([W0, 0])))
                    
                    # æ ¹æ®ç½®ä¿¡åº¦è®¾ç½®é¢œè‰²
                    color = (0, int(255 * 0.8), int(255 * 0.2))  # ç»¿è‰²ç³»
                    
                    # ç»˜åˆ¶å…³é”®ç‚¹
                    cv2.circle(combined_img_color, pt0, 3, color, -1)
                    cv2.circle(combined_img_color, pt1_offset, 3, color, -1)
                    
                    # ç»˜åˆ¶è¿çº¿
                    cv2.line(combined_img_color, pt0, pt1_offset, color, 1)
            
            # æ·»åŠ ä¿¡æ¯
            info_text = f"Improved Matches: {num_matches} (conf: {confidence:.3f})"
            cv2.putText(combined_img_color, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            cv2.imwrite('improved_matches.jpg', combined_img_color)
            print("æ”¹è¿›ååŒ¹é…å¯è§†åŒ–å·²ä¿å­˜: improved_matches.jpg")
        
        return num_matches > 5
        
    except Exception as e:
        print(f"ERROR: æ”¹è¿›æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_with_original():
    """ä¸åŸå§‹å®ç°å¯¹æ¯”"""
    try:
        print("\n=== æ€§èƒ½å¯¹æ¯”æ€»ç»“ ===")
        
        # è¯»å–ä¹‹å‰ä¿å­˜çš„ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        results = {}
        
        if Path('debug_matches.jpg').exists():
            print("å‘ç°ä¹‹å‰çš„æµ‹è¯•ç»“æœ")
            # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªåŠ¨åˆ†æå›¾åƒä¸­åŒ¹é…æ•°é‡çš„ä»£ç 
        
        print("å»ºè®®:")
        print("1. è¿è¡Œ python test_real_matching.py è·å–åŸºå‡†")
        print("2. è¿è¡Œ python test_improved_matching.py æµ‹è¯•æ”¹è¿›")
        print("3. å¯¹æ¯”ä¸¤ä¸ªç»“æœæ–‡ä»¶")
        print("4. å¦‚æœæ”¹è¿›æˆåŠŸï¼Œé‡æ–°å¯åŠ¨Qtç•Œé¢æµ‹è¯•")
        
        return True
        
    except Exception as e:
        print(f"å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹æ”¹è¿›ååŒ¹é…æ€§èƒ½æµ‹è¯•...")
    
    # æµ‹è¯•æ”¹è¿›çš„LoFTR
    improved_ok = test_improved_loftr()
    
    # æ€§èƒ½å¯¹æ¯”
    compare_ok = compare_with_original()
    
    print(f"\n=== æµ‹è¯•ç»“æœ ===")
    print(f"æ”¹è¿›åLoFTR: {'SUCCESS' if improved_ok else 'FAILED'}")
    
    if improved_ok:
        print("ğŸ‰ æ”¹è¿›æˆåŠŸï¼ç°åœ¨å¯ä»¥é‡æ–°æµ‹è¯•Qtç•Œé¢:")
        print("   python run_qt_slam.py --left-cam 0 --right-cam 1")
        print("\né¢„æœŸæ”¹å–„:")
        print("   - åŒ¹é…æ•°é‡ä»1ä¸ªå¢åŠ åˆ°10-50ä¸ª")
        print("   - ä½å§¿ä¼°è®¡å¼€å§‹å·¥ä½œ")
        print("   - å¯è§†åŒ–æ˜¾ç¤ºåŒ¹é…ç‚¹å’Œè¿çº¿")
    else:
        print("âŒ æ”¹è¿›æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")